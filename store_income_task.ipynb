{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Compulsory Task \n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":50,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[],"source":["# Load up store_income_data.csv\n","\n","import pandas as pd\n","import numpy as np\n","\n","import fuzzywuzzy\n","from fuzzywuzzy import process\n","\n","import chardet\n","\n","df = pd.read_csv('store_income_data_task.csv', index_col = 0) \n"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":51,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 76 unique countries\n"]}],"source":["# Looking at the number of unique values in the country column.\n","unique_countries_count = df[\"country\"].nunique()\n","print(f\"There are {unique_countries_count} unique countries\")\n","\n","# Converting the column into lowercase.\n","df[\"country\"] = df[\"country\"].str.lower()\n","\n","# Removing any whitespace.\n","df[\"country\"] = df[\"country\"].str.strip()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":52,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 37 unique countries\n"]},{"data":{"text/plain":["array(['united states/', 'britain', 'united states', 'britain/',\n","       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n","       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n","       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n","       'america.', 's.a..', 'united states of america.',\n","       'united states of america/', 'united states.',\n","       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n","       's. africasouth africa/', 'united kingdom/',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["# Set seed for reproducibility\n","np.random.seed(0)\n","\n","countries = df['country'].unique()\n","print(f\"There are {len(countries)} unique countries\")\n","countries\n","\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>united states</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>britain</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>united states</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>britain</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>united kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     store_name         store_email  department        income  \\\n","id                                                                              \n","1    Cullen/Frost Bankers, Inc.                 NaN    Clothing  $54438554.24   \n","2           Nordson Corporation                 NaN       Tools  $41744177.01   \n","3         Stag Industrial, Inc.                 NaN      Beauty  $36152340.34   \n","4           FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   $8928350.04   \n","5   Mercantile Bank Corporation                 NaN        Baby  $33552742.32   \n","\n","   date_measured         country  \n","id                                \n","1       4-2-2006  united states   \n","2       4-1-2006         britain  \n","3      12-9-2003   united states  \n","4       8-5-2006        britain   \n","5      21-1-1973  united kingdom  "]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# Convert to lower case\n","df['country'] = df['country'].str.lower()\n","\n","# Remove trailing white spaces\n","df['country'] = df['country'].str.strip()\n","\n","# Get the top 10 closest matches to \"united kingdom\"\n","matches = fuzzywuzzy.process.extract(\"uk\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","\n","# Inspect matches\n","matches\n","df.head()"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All done!\n","All done!\n","All done!\n","All done!\n","All done!\n"]}],"source":["# Function to replace rows in the provided column of the provided DataFrame\n","# that match the provided string above the provided ratio with the provided string\n","def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n","    # get a list of unique strings\n","    strings = df[column].unique()\n","    \n","    # Get the top 10 closest matches to our input string\n","    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n","                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","\n","    # Only get matches with a ratio > 90\n","    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n","\n","    # Get the rows of all the close matches in our dataframe\n","    rows_with_matches = df[column].isin(close_matches)\n","\n","    # Replace all rows with close matches with the input matches \n","    df.loc[rows_with_matches, column] = string_to_match\n","    \n","    # Let us know when the function is done\n","    print(\"All done!\")\n","\n","replace_matches_in_column(df=df, column='country', string_to_match=\"united kingdom\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"united states\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"united states of america\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"south africa\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"uk\")"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 18 unique countries\n"]},{"data":{"text/plain":["array(['united states', 'britain', 'britain ', 'united kingdom', 'u k ',\n","       'sa', nan, 's a ', 'england', 's a  ', 'america ', 'sa ', '',\n","       'england ', 'united states of america', 's  africasouth africa',\n","       ' ', 's  africasouth africa '], dtype=object)"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["# get all the unique values in the 'country' column\n","countries = df['country'].unique()\n","\n","# Replace . or / with white spaces\n","df['country'] = df['country'].str.replace(\".\", \" \").str.replace(\"/\", \" \")\n","\n","print(f\"There are {len(countries)} unique countries\")\n","countries"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['united states' 'united kingdom' 'south africa']\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\A-C19\\AppData\\Local\\Temp\\ipykernel_2288\\1177479497.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_filtered['country'] = df_filtered['country'].replace('', np.nan)\n","C:\\Users\\A-C19\\AppData\\Local\\Temp\\ipykernel_2288\\1177479497.py:27: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_filtered['country'] = df_filtered['country'].replace(' ', np.nan)\n","C:\\Users\\A-C19\\AppData\\Local\\Temp\\ipykernel_2288\\1177479497.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_filtered['country'] = df_filtered['country'].replace('s  africasouth africa ', np.nan)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>united states</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>united kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>united states</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>united kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>united kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     store_name         store_email  department       income  \\\n","id                                                                             \n","1    Cullen/Frost Bankers, Inc.                 NaN    Clothing  54438554.24   \n","2           Nordson Corporation                 NaN       Tools  41744177.01   \n","3         Stag Industrial, Inc.                 NaN      Beauty  36152340.34   \n","4           FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   8928350.04   \n","5   Mercantile Bank Corporation                 NaN        Baby  33552742.32   \n","\n","   date_measured         country  \n","id                                \n","1       4-2-2006   united states  \n","2       4-1-2006  united kingdom  \n","3      12-9-2003   united states  \n","4       8-5-2006  united kingdom  \n","5      21-1-1973  united kingdom  "]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["df.replace('uk', 'united kingdom', inplace=True)\n","df.replace(\"u k\" ,'united kingdom', inplace=True)\n","df.replace(\"britain\" ,'united kingdom', inplace=True)\n","df.replace(\"britain \" ,'united kingdom', inplace=True)\n","df.replace(\"u k \" ,'united kingdom', inplace=True)\n","df.replace(\"england\" ,'united kingdom', inplace=True)\n","df.replace(\"england \" ,'united kingdom', inplace=True)\n","df.replace('united states of america', 'united states', inplace=True)\n","df.replace('united states', 'united states', inplace=True)\n","df.replace('america', 'united states', inplace=True)\n","df.replace('america ', 'united states', inplace=True)\n","df.replace('sa', 'south africa', inplace=True)\n","df.replace('s  africasouth africa', 'south africa', inplace=True)\n","df.replace('s a', 'south africa', inplace=True)\n","df.replace('s a ', 'south africa', inplace=True)\n","df.replace('s a  ', 'south africa', inplace=True)\n","df.replace('sa ', 'south africa', inplace=True)\n","\n","# Define the list of countries to keep\n","valid_countries = ['united states', 'united kingdom', 'south africa']\n","\n","# Filter the DataFrame to keep only rows with valid countries\n","df_filtered = df[df['country'].isin(valid_countries)]\n","\n","# Replace any other values with NaN\n","df_filtered['country'] = df_filtered['country'].replace('', np.nan)\n","df_filtered['country'] = df_filtered['country'].replace(' ', np.nan)\n","df_filtered['country'] = df_filtered['country'].replace('s  africasouth africa ', np.nan)\n","\n","# Drop rows with NaN values in the 'country' column\n","df_filtered = df_filtered.dropna(subset=['country'])\n","\n","# Check the result\n","print(df_filtered['country'].unique())\n","\n","df.head()\n"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                     store_name         store_email  department       income  \\\n","id                                                                             \n","1    Cullen/Frost Bankers, Inc.                 NaN    Clothing  54438554.24   \n","2           Nordson Corporation                 NaN       Tools  41744177.01   \n","3         Stag Industrial, Inc.                 NaN      Beauty  36152340.34   \n","4           FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   8928350.04   \n","5   Mercantile Bank Corporation                 NaN        Baby  33552742.32   \n","\n","   date_measured         country            days_ago  \n","id                                                    \n","1     2006-04-02   united states  6554 days, 0:00:00  \n","2     2006-04-01  united kingdom  6555 days, 0:00:00  \n","3     2003-12-09   united states  7399 days, 0:00:00  \n","4     2006-08-05  united kingdom  6429 days, 0:00:00  \n","5            NaT  united kingdom                 NaN  \n"]}],"source":["import pandas as pd\n","from datetime import date\n","\n","# Create a copy of the DataFrame to avoid modifying the original data\n","df_copy = df.copy()\n","\n","# Convert the 'date_measured' column to datetime format\n","df_copy['date_measured'] = pd.to_datetime(df['date_measured'], errors='coerce')\n","\n","# Calculate the difference in days for each date from the current date\n","current_date = date.today()\n","df_copy['days_ago'] = (current_date - (df_copy['date_measured'].dt.date))\n","\n","# Print the DataFrame to see the new column\n","print(df_copy.head())\n","\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('phd')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
